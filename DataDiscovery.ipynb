{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Discovery and Exploration: State-of-the-art, Challenges and Opportunities\n",
    "## Part 1: Dataset Search\n",
    "### Framework Overview -- D3L\n",
    "#### Input Dataset\n",
    "The input dataset consists of structured data with various attributes. Below is a glimpse of the top 10 rows, showcasing the structure and type of data we are dealing with:\n",
    "\n",
    "| Column1 | Column2 | Column3 |\n",
    "|---------|---------|---------|\n",
    "| Value1  | Value2  | Value3  |\n",
    "| ...     | ...     | ...     |\n",
    "\n",
    "D3L utilizes a comprehensive approach based on:\n",
    "\n",
    "1. **Attribute Header Similarity**\n",
    "2. **Value Similarity**\n",
    "3. **Format Similarity**\n",
    "4. **Value Distribution**\n",
    "#### Output Datasets: Top k searched dataset results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generate LSH indexes for all evidence in D3L"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import and initialize D3L\n",
    "from d3l.d3l.indexing.similarity_indexes import NameIndex, FormatIndex, ValueIndex, EmbeddingIndex, DistributionIndex\n",
    "from d3l.d3l.input_output.dataloaders import CSVDataLoader\n",
    "from d3l.d3l.querying.query_engine import QueryEngine\n",
    "from d3l.d3l.utils.functions import pickle_python_object, unpickle_python_object\n",
    "import os\n",
    "# import pandas as pd\n",
    "\n",
    "data_path = \"Datasets\"\n",
    "threshold = 0.5\n",
    "#  collection of tables\n",
    "\n",
    "dataloader = CSVDataLoader(\n",
    "        root_path=data_path,\n",
    "        encoding='utf-8'\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generating/loading NameIndex of tables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_lsh = os.path.join(data_path, f'./Name.lsh')\n",
    "if os.path.isfile(name_lsh):\n",
    "    name_index = unpickle_python_object(name_lsh)\n",
    "    print(\"Name LSH index: LOADED!\")\n",
    "else:\n",
    "    name_index = NameIndex(dataloader=dataloader, index_similarity_threshold=threshold)\n",
    "    pickle_python_object(name_index, name_lsh)\n",
    "    print(\"Name LSH index: SAVED!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generating/loading FormatIndex of tables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "format_lsh = os.path.join(data_path, './format.lsh')\n",
    "if os.path.isfile(format_lsh):\n",
    "    format_index = unpickle_python_object(format_lsh)\n",
    "    print(\"Format LSH index: LOADED!\")\n",
    "else:\n",
    "    format_index = FormatIndex(dataloader=dataloader, index_similarity_threshold=threshold)\n",
    "    pickle_python_object(format_index, format_lsh)\n",
    "    print(\"Format LSH index: SAVED!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generating/loading ValueIndex of tables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "value_lsh = os.path.join(data_path, './value.lsh')\n",
    "if os.path.isfile(value_lsh):\n",
    "    value_index = unpickle_python_object(value_lsh)\n",
    "    print(\"Value LSH index: LOADED!\")\n",
    "else:\n",
    "    value_index = ValueIndex(dataloader=dataloader, index_similarity_threshold=threshold)\n",
    "    pickle_python_object(value_index, value_lsh)\n",
    "    print(\"Value LSH index: SAVED!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generating/loading ValueIndex of tables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "   # DistributionIndex\n",
    "distribution_lsh = os.path.join(data_path, './distribution.lsh')\n",
    "if os.path.isfile(distribution_lsh):\n",
    "    distribution_index = unpickle_python_object(distribution_lsh)\n",
    "    print(\"Distribution LSH index: LOADED!\")\n",
    "else:\n",
    "    distribution_index = DistributionIndex(dataloader=dataloader, index_similarity_threshold=threshold)\n",
    "    pickle_python_object(distribution_index, distribution_lsh)\n",
    "    print(\"Distribution LSH index: SAVED!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Generating/loading EmbeddingIndex of tables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embed_name = './embedding_.lsh'\n",
    "embedding_lsh = os.path.join(data_path, embed_name)\n",
    "\n",
    "if os.path.isfile(embedding_lsh):\n",
    "    embedding_index = unpickle_python_object(embedding_lsh)\n",
    "    print(\"Embedding LSH index: LOADED!\")\n",
    "else:\n",
    "    embedding_index = EmbeddingIndex(dataloader=dataloader,\n",
    "                                     index_similarity_threshold=threshold)\n",
    "    pickle_python_object(embedding_index, embedding_lsh)\n",
    "    print(\"Embedding LSH index: SAVED!\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### show the input table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_table = 'T2DV2_122'\n",
    "table_df = dataloader.read_table(searched_table)\n",
    "print(table_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Searched results, K =10\n",
    "qe = QueryEngine(name_index, format_index, value_index, embedding_index, distribution_index)\n",
    "results, extended_results = qe.table_query(table=dataloader.read_table(table_name=searched_table),\n",
    "                                           aggregator=None, k=10, verbose=True)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Individual search results\n",
    "# Name index query\n",
    "name_results = name_index.query(query=\"<string>\", k=\"<integer>\") # The query arg should be a column name. Tokenization will be performed automatically.\n",
    "\n",
    "# Format index query\n",
    "format_results = format_index.query(query=\"<list/set>\", k=\"<integer>\") # The query arg should be a collection of string values. The corresponding format descriptors will be extracted automatically.\n",
    "\n",
    "# Value index query\n",
    "value_results = value_index.query(query=\"<list/set>\", k=\"<integer>\") # The query arg should be a collection of string values. Value pre-processing will be performed automatically.\n",
    "\n",
    "# Embeddings index query\n",
    "embedding_results = embedding_index.query(query=\"<list/set>\", k=\"<integer>\") # The query arg should be a collection of string values. The corresponding embeddings will be extracted automatically.\n",
    "\n",
    "# Distribution index query\n",
    "distribution_results = distribution_index.query(query=\"<list/set>\", k=\"<integer>\") # The query arg should be a collection of numerical values. The corresponding distribution will be extracted automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Dataset Navigation\n",
    "### Framework Overview -- Aurum\n",
    "TBC Still under work"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3: Dataset Annotation\n",
    "### Framework Overview -- TableMiner+\n",
    "#### Input dataset: 26 tables from 13 domain, while each domain has 2 tables (TBC)\n",
    "The 13 domains include:\n",
    "1. **Airport**\n",
    "2. **City**\n",
    "3. **CollegeOrUniversity**\n",
    "4. **Company**\n",
    "5. **Continent**\n",
    "6. **Country**\n",
    "7. **Hospital**\n",
    "8. **LandmarksOrHistoricalBuildings**\n",
    "9. **Monarch**\n",
    "10. **Movie**\n",
    "11. **Museum**\n",
    "12. **Scientist**\n",
    "13. **VideoGame**\n",
    "\n",
    "TableMiner+ has 4 steps:\n",
    "1. **Subject Column Detection: Including column (data) type detection** \n",
    "2. **NE-Column interpretation - the LEARNING phase:**\n",
    "***2.1 preliminary cell annotation***\n",
    "***2.2 column semantic type annotation***\n",
    "***2.3 property annotation***\n",
    "3. **NE-Column interpretation - the UPDATE phase: revise annotation until all annotation is stabilized**\n",
    "4. **Relation enumeration and annotating literal-columns(not included yet)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### show the example annotation table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from TableMiner.LearningPhase.Update import TableLearning,  updatePhase\n",
    "Table = pd.read_csv(\"E:\\Project\\EDBTDemo\\Datasets\\T2DV2_122.csv\") #125\n",
    "print(Table, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Perform NE-Column interpretation (Table Learning includes the process of subject column detection of a table)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tableLearning = TableLearning(Table)\n",
    "tableLearning.table_learning()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Perform NE-Column interpretation - the UPDATE phase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "updatePhase(tableLearning)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### check the annotation of column (this needs re-factor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "annotation_class = tableLearning.get_annotation_class()\n",
    "for column_index, learning_class in annotation_class.items():\n",
    "    column = learning_class.get_column()\n",
    "    print(f\"column is {column}\")\n",
    "    cellAnnotation  = learning_class.get_cell_annotation()\n",
    "    ColumnSemantics = learning_class.get_winning_concepts()\n",
    "    print(f\"Cell annotation of the column: {cellAnnotation}\")\n",
    "    print(f\"Column semantic type of the column: {ColumnSemantics}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4: Schema Inference\n",
    "### Framework Overview -- Starmie\n",
    "#### Input dataset: all 200 tables covering 13 specific domains\n",
    "Starmie perform column clustering on the embedding of each column.\n",
    "Embedding generation: Description ...  "
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
